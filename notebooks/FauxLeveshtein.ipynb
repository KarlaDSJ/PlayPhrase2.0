{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2678c0d",
   "metadata": {},
   "source": [
    "# Levenshtein con palabras\n",
    "\n",
    "Este enfoque ocupa la idea de Levenshtein pero con palabras en lugar de carácteres es decir que buscará dentro de cada video los subtítulos que cambien menos con la query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e2125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/valencia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/valencia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/valencia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/valencia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.utils import *\n",
    "from src.data import Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd68fc",
   "metadata": {},
   "source": [
    "Cargamos el corpus tokenizado y limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d31ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'L9YhoRatRzE',\n",
       " 'original_title': 'Siempre Fui Yo | Adelanto | Disney+',\n",
       " 'subtitles': [{'start': '0.13',\n",
       "   'dur': '3.77',\n",
       "   'text': ['tu', 'papá', 'tuvo', 'un', 'accidente']},\n",
       "  {'start': '12.5', 'dur': '5.939', 'text': ['te', 'recuerdo', 'que', 'está']},\n",
       "  {'start': '15.59', 'dur': '5.339', 'text': ['aquí']},\n",
       "  {'start': '18.439',\n",
       "   'dur': '6.361',\n",
       "   'text': ['estaba', 'como', 'rabioso', 'con']},\n",
       "  {'start': '20.929',\n",
       "   'dur': '7.65',\n",
       "   'text': ['especial', 'con', 'lucas', 'martín']},\n",
       "  {'start': '24.8',\n",
       "   'dur': '3.779',\n",
       "   'text': ['necesito', 'saber', 'qué', 'fue', 'lo', 'que', 'pasó']},\n",
       "  {'start': '29.42', 'dur': '2.479', 'text': ['aplausos']}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = Data(\"../pkl/clean_videos.pkl\")\n",
    "videos.corpus[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07cdb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIx(video, ix):\n",
    "    \"\"\"\n",
    "    video: video en el que se buscara\n",
    "    ix: indice de la palabra que buscamos\n",
    "    regresa el subtitulo y su indice de la palabra buscada\n",
    "    \"\"\"\n",
    "    subtitles = video[\"subtitles\"]\n",
    "    r = -1\n",
    "    while ix>0:\n",
    "        r += 1\n",
    "        ix -= len(subtitles[r][\"text\"])\n",
    "    return (r, subtitles[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720b3314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 9/9 [00:00<00:00, 25.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tu', 'papá', 'tuvo', 'un', 'accidente']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.get_all_subtitles()\n",
    "videos.all_subtitles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05cdfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideosDict():\n",
    "    \"\"\"\n",
    "    regresa un diccionario donde el id de un video es su llave\n",
    "    \"\"\"\n",
    "    return {v['id']:v for v in flatten(videos.corpus)}\n",
    "videosDict = getVideosDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf8c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDistances(distances, token1Length, token2Length):\n",
    "    \"\"\"\n",
    "    Función auxiliar para imprimir la matriz de las distancias de Levenshtein\n",
    "    \"\"\"\n",
    "    for t1 in range(token1Length + 1):\n",
    "        for t2 in range(token2Length + 1):\n",
    "            print(int(distances[t1][t2]), end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878d3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faux_levenshtein(q, d, verbose=False):\n",
    "    \"\"\"\n",
    "    q: query a buscar\n",
    "    d: string en la que buscamos\n",
    "    verbose: si la función debe imprimir la matrix\n",
    "    faux leveshtein ejecuta leveshtein ejecuta leveshtein con matrix, pero toda la columna \n",
    "    del espacio de busqueda es inicalizada con 0 lo que nos permite encontrar coincidencias\n",
    "    como subcandena y comparadas desde el inico.\n",
    "    Regresa la distancia minima de leveshtein entre nuestra query y una subcadena de d y el \n",
    "    indice de dicha subcadena.\n",
    "    \"\"\"\n",
    "    distances = np.zeros((len(q) + 1, len(d) + 1))\n",
    "    for t1 in range(len(q) + 1):\n",
    "        distances[t1][0] = t1\n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(q) + 1):\n",
    "        for t2 in range(1, len(d) + 1):\n",
    "            if (q[t1-1] == d[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "    if(verbose):\n",
    "        printDistances(distances, len(q), len(d))\n",
    "    \n",
    "    min_arg = np.argmin(distances[len(q)])\n",
    "    return (distances[len(q)][min_arg], min_arg-len(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d19cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_faux_levenshtein(q):\n",
    "    \"\"\"\n",
    "    q: arreglo de cadenas que queremos encontrar en el corpues\n",
    "    regresa un dataframe ordenado por su destancia de faux levenshtein\n",
    "    \"\"\"\n",
    "    indexes = []\n",
    "    minvals = []\n",
    "    for (k,d) in tqdm(videos.documents.items()):\n",
    "        minval, mix =faux_levenshtein(q, d)\n",
    "        indexes.append(mix)\n",
    "        minvals.append(minval)\n",
    "    df = pd.DataFrame(data={\"id\":videos.documents.keys(), 'faux leveshtein':minvals, 'fl index':indexes})\n",
    "    return df.sort_values(by=['faux leveshtein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4004c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(q):\n",
    "    \"\"\"\n",
    "    q: cadena que queremos encontrar en el corpus\n",
    "    regresa un generador que podemos iterar para ir encontrando los resultados de la busqueda\n",
    "    \"\"\"\n",
    "    def iterator(top):\n",
    "        for _,serie in top.iterrows():\n",
    "            ix = serie['fl index']\n",
    "            video = videosDict[serie[\"id\"]]\n",
    "            subtitle_id, subtitle = findIx(video, ix)\n",
    "            next_sub = None\n",
    "            if (subtitle_id+1) < len(video[\"subtitles\"]):\n",
    "                next_sub = video[\"subtitles\"][subtitle_id+1][\"text\"]\n",
    "            yield {\n",
    "                \"id\":serie[\"id\"], \n",
    "                \"subtitle\": subtitle, \n",
    "                \"next_subtitle\": next_sub,\n",
    "                \"subtitle_id\":subtitle_id, \n",
    "                'faux leveshtein':serie['faux leveshtein'] \n",
    "            }\n",
    "    q = q.split(\" \")\n",
    "    top = search_faux_levenshtein(q)\n",
    "    return iterator(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f2bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3278/3278 [00:15<00:00, 205.98it/s]\n"
     ]
    }
   ],
   "source": [
    "r = search(\"grande y gordo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0ec3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6PDVRDv-nik',\n",
       " 'subtitle': {'start': '872.71',\n",
       "  'dur': '4.14',\n",
       "  'text': ['veis', 'el', 'error', 'no', 'fue', 'ni', 'mucho', 'menos', 'tan']},\n",
       " 'next_subtitle': ['grande',\n",
       "  'y',\n",
       "  'eso',\n",
       "  'teniendo',\n",
       "  'en',\n",
       "  'cuenta',\n",
       "  'que',\n",
       "  'las'],\n",
       " 'subtitle_id': 382,\n",
       " 'faux leveshtein': 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bff65d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5(query):\n",
    "    fl = search(\"grande y gordo\")\n",
    "    return [next(fl)[\"subtitle\"][\"text\"] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0fbeba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4535"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../pkl/test.pkl\", \"rb\") as f:\n",
    "    test_all = pickle.load(f)\n",
    "\n",
    "len(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cb904f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1814\n",
    "resp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff5a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ix, q in enumerate(test_all[1814*2:]):\n",
    "    if ix%9==0:\n",
    "        pickle.dump(resp, open(\"../pkl/faux_levenshtein.pkl\", \"wb\"))\n",
    "        print(f\"salvando {ix} elementos\")\n",
    "    resp.append(top5(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7441b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
