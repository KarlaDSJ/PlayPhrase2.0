{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec para RI\n",
    "\n",
    "Este enfoque toma los subtítulos de cada vídeo y los transforma a un vector generado por Dov2Vec, posteriormente para regresar los subtítulos que más se parecen a un query comparamos los vectores por su distancia y regresamos los 5 vectores que más cerca están del vector query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "#Para el corpus\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.utils import *\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pickle\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtittle():\n",
    "    \"\"\"\n",
    "    Regresa un diccionario con la información de cada subtítulo \n",
    "    (id del video: lista de subtítulos)\n",
    "    y otro diccionario que contiene los subtítulos, las llaves de estos \n",
    "    subtítulos son de la forma: idvideo-idsubtítulo, esto para poder regresar \n",
    "    la información con el primer diccionario\n",
    "    \"\"\"\n",
    "    path = \"../corpus/data\"\n",
    "    sub = defaultdict()\n",
    "    info = defaultdict()\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "    for file in onlyfiles:\n",
    "        with open(path+\"/\"+file, 'rb') as f:\n",
    "            chanel = json.loads(f.read().decode('utf-8', 'replace'))\n",
    "            for video in chanel:\n",
    "                if 'subtitles' in video: #Si hay subtítulos\n",
    "                    info[video[\"id\"]] = []\n",
    "                    for i, s in enumerate(video['subtitles']):\n",
    "                        name = video[\"id\"] + \"-\" + str(i) #creamos llave del subtítulo\n",
    "                        sub[name] = get_tokens_clean(s['text'], stop_words=True) #Limpiamos\n",
    "                        info[video[\"id\"]].append(s)\n",
    "    return sub, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub, info = get_subtittle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frida', 'kahlo', 'andaba', 'regreso', 'escuela', 'ciudad', 'méxico'] {'start': '7.791', 'dur': '3.09', 'text': 'Frida Kahlo andaba de regreso de\\nla escuela en la ciudad de México'}\n"
     ]
    }
   ],
   "source": [
    "print(sub[\"68tp7jWrcjA-2\"], info[\"68tp7jWrcjA\"][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparamos los datos para utilizar el objeto doc2vec\n",
    "(Esta parte se puede omitir si ya se entrenó antes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['adónde', 'vas', 'momo'], tags=['_DZF9EqExZM-0']),\n",
       " TaggedDocument(words=['débil'], tags=['_DZF9EqExZM-1']),\n",
       " TaggedDocument(words=['crees', 'podrás', 'sobrevivir'], tags=['_DZF9EqExZM-2']),\n",
       " TaggedDocument(words=['cumples', 'reglas', 'sociedad'], tags=['_DZF9EqExZM-3']),\n",
       " TaggedDocument(words=['vencido', 'encontramos', 'guarida'], tags=['_DZF9EqExZM-4'])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos los tokens de cada título en el formato requerido por gensim \n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in sub.items()]\n",
    "tagged_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos y guardamos\n",
    "(Esta parte se puede omitir si ya se entrenó antes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train doc2vec model\n",
    "model = Doc2Vec(tagged_data, vector_size=10, window=2, min_count=1, workers=4, epochs = 100)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save(\"models/sub_doc2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540324\n"
     ]
    }
   ],
   "source": [
    "## Load saved doc2vec model\n",
    "model= Doc2Vec.load(\"models/sub_doc2vec.model\")\n",
    "print(len(model.dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5(query, show=False):\n",
    "    \"\"\"\n",
    "    Regresa los 5 subtítulos que más se parecen a una query\n",
    "\n",
    "    Args:\n",
    "        query (str): cadena a buscar\n",
    "        show (bool): muestra en pantalla el resultado?\n",
    "    \"\"\"\n",
    "    test_doc = get_tokens_clean(query) #Limpiamos la query\n",
    "    #Obtenemos los 5 primeros\n",
    "    resp = model.dv.most_similar(positive=[model.infer_vector(test_doc)],topn=5)\n",
    "    info_resp = []\n",
    "    for doc in resp:\n",
    "        aux = doc[0].rsplit('-', 1) #Obtenemos idVideo - idSub\n",
    "        aux[1] = int(aux[1])\n",
    "        if show:\n",
    "            print('Id: {} \\nInfo: {}\\n ---------'.format(aux[0],info[aux[0]][aux[1]]))\n",
    "        info_resp.append(info[aux[0]][aux[1]]['text'])\n",
    "    return info_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id: xLI9PUjwpbM \n",
      "Info: {'start': '1.859', 'dur': '4.178', 'text': 'Una receta de pastel suave, esponjoso\\ny humedo.'}\n",
      " ---------\n",
      "Id: DUhvKm4VLeg \n",
      "Info: {'start': '1.668', 'dur': '3.121', 'text': 'Una receta de Pastel suave y esponjoso.'}\n",
      " ---------\n",
      "Id: cHv2QxwXg9U \n",
      "Info: {'start': '642.42', 'dur': '7.1', 'text': 'el ambiente de calor en la mesa la cena'}\n",
      " ---------\n",
      "Id: 8Bbgqu3O7fk \n",
      "Info: {'start': '423.9', 'dur': '5.489', 'text': 'un esqueleto que durante ni más ni menos'}\n",
      " ---------\n",
      "Id: sH8PM_ehUys \n",
      "Info: {'start': '8.309', 'dur': '4.801', 'text': 'que es lo más difícil de ser una raqueta'}\n",
      " ---------\n"
     ]
    }
   ],
   "source": [
    "r = get_top5(\"Receta de pastel con almendras\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Una receta de pastel suave, esponjoso\\ny humedo.', 'Una receta de Pastel suave y esponjoso.', 'el ambiente de calor en la mesa la cena', 'un esqueleto que durante ni más ni menos', 'que es lo más difícil de ser una raqueta']\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probamos con el conjunto test\n",
    "...para posteriormente evaluarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../pkl/test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4535/4535 [02:51<00:00, 26.38it/s]\n"
     ]
    }
   ],
   "source": [
    "#Consulta\n",
    "test_results = []\n",
    "\n",
    "for query in tqdm(test):\n",
    "    r = get_top5(query)\n",
    "    test_results.append(r)\n",
    "\n",
    "pickle.dump(test_results, open(\"../pkl/resultsDoc2Vec.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a un lado oigan alejen a los demás viene ['a un lado oigan alejen a los demás viene', 'cruzado y deciden crear ahi unos', '¿Qué pasa?\\nNo te lo guardes', '¡pero miren estas tazas!', 'Retire y colóquelos en un rack.']\n",
      "-------------\n",
      "saber lo que se está toda máquina ['saber lo que se está toda máquina', 'eso es hasta para orinar es lenta', 'Si no sabes mucho acerca de la termodinámica, el Pájaro Bebedor podría parecer que podría durar para siempre, sin una fuente externa de energía que lo alimente, una máquina de movimiento perpetuo, en otras palabras.', 'Ahora viene el tiempo de revisión. Puede hacer clic en cualquier de estos enlaces y volver a la parte de', 'Pero, en orden para ir de un simple tubo al clásico, arrugado icono que pensamos']\n",
      "-------------\n",
      "estás llorando que ya me involucre ['estás llorando que ya me involucre', 'Oye, espera. ¿Qué haces?', 'la misa no lo hagas cuando acabe la misa', 'raúl ten cuidado que cuando grabas un', 'Perdí a mi hija, perdí mi casa']\n",
      "-------------\n",
      "especie ['en otra especie.', 'sí como si esto fuera una especie de', 'que es la verdadera enfermedad que afecta al país.', 'del estado y el estado garantizará su', 'un potencial graduado.']\n",
      "-------------\n",
      "avergonzado lo suficiente no apenas ['avergonzado lo suficiente no apenas', 'también te hace menos vulnerable si', 'normal es normal', 'normal normal que te guste el ancho', 'me lo esperaba más alto.']\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "with open(\"../pkl/resultsDoc2Vec.pkl\", \"rb\") as f:\n",
    "    test_resultsxO = pickle.load(f)\n",
    "\n",
    "for i in range(5):\n",
    "    print(test[i], test_resultsxO[i])\n",
    "    print(\"-------------\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
