{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de los algoritmos de agrupar\n",
    "\n",
    "Tenemos 3 propuestas, donde cada una tiene un total de 10 clusters: la primera hace los grupos de acuerdo a las palabras clave de los subtítulos, la segunda hace lo mismo pero por vídeos, ambas utilizando el algoritmo de k-means, mientras que la última lo hace por videos pero utilizando el espectro y k-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/karla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/karla/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "#Para el corpus\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import Data \n",
    "#Para calcular TF-IDF\n",
    "from src.tfidf import TFIDF\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "# nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords #Listas de stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y si agrupamos por el título? cómo vectorizamos el título? se puede igual con tf.idf?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los clusters de cada intento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    \"\"\"\n",
    "    Carga clusters, regresa los id y documentos\n",
    "    de cada cluster\n",
    "\n",
    "    Args:\n",
    "        path (str): ruta del archivo\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return model[0], model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por subtítulo\n",
    "named_subKM, clusters_subKM = load(\"../pkl/sub_classKMeans.pkl\")\n",
    "#Por vídeo utilizando espectro\n",
    "named_videoKM, clusters_videoKM = load(\"../pkl/video_classKMeans.pkl\")\n",
    "#Por vídeo utilizando espectro y k-means\n",
    "named_videoS, clusters_videoS = load(\"../pkl/video_classSpectre.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intento 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los canales de los que se tomaron los videos sabemos que uno de ellos es de comida y otro trata temas políticos, por lo que como una primera prueba podemos ver si los vídeos de esos canales quedaron en los mismos clusters (sería de alguna manera verificar la pureza de 2 clusters)\n",
    "\n",
    "Obtenemos los id de los videos de los canales mencionados:\n",
    "\n",
    "|           id            |    canal      |\n",
    "|-------------------------|---------------|\n",
    "|UCJQQVLyM6wtPleV4wFBK06g | visualpolitik |\n",
    "|UC_Zc2fmbDpu_arkwvCDcX5g | cocina        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_goal = {'cocina':[], 'política': []}\n",
    "files = [('cocina','UC_Zc2fmbDpu_arkwvCDcX5g'), ('política','UCJQQVLyM6wtPleV4wFBK06g')]\n",
    "for name, file in files:\n",
    "    with open(\"../corpus/data/\"+file+\".json\", 'rb') as f:\n",
    "        chanel = json.loads(f.read().decode('utf-8', 'replace'))\n",
    "        for video in chanel:\n",
    "            clusters_goal[name].append(video[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IAHQXsLS3P8', 'dhYWMdHVvGg', 'ULle2vGte8k', 'gun3ouyEoIc', 'H2L_btIXzzc', 'r5IM3yYTQoU', 'ld2pqKmEdDg', 'aNEHF2g0Bos', 'GbQOvcv1cTU', 'DUhvKm4VLeg']\n"
     ]
    }
   ],
   "source": [
    "print(clusters_goal['cocina'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_goal_clusters(named_video):\n",
    "    \"\"\"\n",
    "    Muestra en pantalla la distribución de los vídeos contenidos\n",
    "    en los clusters meta\n",
    "    \n",
    "    Args:\n",
    "        named_video (dict): diccionario con el nombre del clusters y el id de los videos\n",
    "    \"\"\"\n",
    "    resp = [[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0]]\n",
    "    for i, name in enumerate(clusters_goal):\n",
    "        for id in clusters_goal[name]:\n",
    "            for c, docs in named_video.items():\n",
    "                if id in docs:\n",
    "                    resp[i][c] += 1\n",
    "    print(\"\"\"Distribución de videos en los clusters\n",
    "         Cocina:\n",
    "            {}\n",
    "        Política:\n",
    "            {}\"\"\".format(resp[0], resp[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo intentamos para los videos utilizando k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de videos en los clusters\n",
      "         Cocina:\n",
      "            [40, 0, 129, 0, 1, 74, 7, 0, 0, 1]\n",
      "        Política:\n",
      "            [1, 0, 13, 0, 1, 694, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "check_goal_clusters(named_videoKM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1698"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(named_videoKM[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior podemos tomar que el cluster 2 es el que corresponde a Cocina y que el cluster 5 a política, aunque el cluster 5 cuenta con 1698 videos de los que 694 son de política y 74 de cocina, lo que deja 930 vídeos que podrían ser de política o podrían ser un error al momento de agrupar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo intentamos ahora con los vídeos utilizando el espectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de videos en los clusters\n",
      "         Cocina:\n",
      "            [29, 14, 24, 20, 4, 24, 31, 22, 84, 0]\n",
      "        Política:\n",
      "            [52, 44, 63, 50, 31, 45, 75, 31, 319, 0]\n"
     ]
    }
   ],
   "source": [
    "check_goal_clusters(named_videoS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que aquí los videos de ambas categorías están distribuidos a lo largo de todos los clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intento 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos extraer las principales palabras de los clusters para ver si tienen relación y de verdad representan un grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 12.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el corpus limpio\n",
    "videos = Data(\"../pkl/clean_videos.pkl\")\n",
    "videos.get_all_subtitles()\n",
    "#Creamos el objeto tfidf\n",
    "tfidf_obj = TFIDF(videos)\n",
    "# Cargamos los valores tfidf previamente calculados\n",
    "tfidf_obj.tfidf = \"../pkl/tfidf.pkl\" #Vectores por texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "more = [\"si\", \"bien\", \"ahora\", \"así\", \"aquí\", \"pues\"]\n",
    "stopwords_list = stopwords.words('spanish') + more\n",
    "\n",
    "def take2(tfidf):\n",
    "    for w, _ in tfidf:\n",
    "        if w not in stopwords_list:\n",
    "            return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos tfidf por documento y obtenemos la palabra clave de cada uno\n",
    "#las agrupamos por clusters\n",
    "def get_keywords_clusters(named_video):\n",
    "    '''\n",
    "    Regresa un diccionario con los subtítulos y su vector tfidf\n",
    "    '''\n",
    "    \n",
    "    keyword = [[],[],[],[],[],[],[],[],[],[]]\n",
    "    #Iteramos sobre los canales\n",
    "    for c, docs in named_video.items():\n",
    "        for id in docs:\n",
    "            key = take2(sorted(tfidf_obj.tfidf[id].items(), key=itemgetter(1), reverse=True))\n",
    "            keyword[c].append(key)\n",
    "        keyword[c] = sorted(Counter(keyword[c]).items(), key=itemgetter(1), reverse=True)[:5]\n",
    "    return keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      " Palabras clave: [('música', 39), ('años', 38), ('voy', 30), ('vamos', 22), ('vídeo', 15)]\n",
      "----------------\n",
      "Cluster: 1\n",
      " Palabras clave: [('música', 20), ('voy', 10), ('mundo', 6), ('años', 6), ('vamos', 5)]\n",
      "----------------\n",
      "Cluster: 2\n",
      " Palabras clave: [('música', 140), ('voy', 44), ('vídeo', 38), ('años', 35), ('país', 23)]\n",
      "----------------\n",
      "Cluster: 3\n",
      " Palabras clave: [('música', 13), ('vamos', 7), ('voy', 7), ('país', 5), ('años', 4)]\n",
      "----------------\n",
      "Cluster: 4\n",
      " Palabras clave: [('música', 17), ('voy', 16), ('años', 11), ('vamos', 10), ('amigos', 9)]\n",
      "----------------\n",
      "Cluster: 5\n",
      " Palabras clave: [('música', 629), ('país', 530), ('años', 163), ('vídeo', 107), ('voy', 43)]\n",
      "----------------\n",
      "Cluster: 6\n",
      " Palabras clave: [('música', 38), ('voy', 28), ('años', 25), ('vamos', 22), ('país', 8)]\n",
      "----------------\n",
      "Cluster: 7\n",
      " Palabras clave: [('música', 4), ('hola', 2), ('anime', 2), ('aplausos', 1), ('vamos', 1)]\n",
      "----------------\n",
      "Cluster: 8\n",
      " Palabras clave: [('música', 47), ('voy', 23), ('vamos', 19), ('años', 18), ('amigos', 13)]\n",
      "----------------\n",
      "Cluster: 9\n",
      " Palabras clave: [('música', 72), ('vamos', 28), ('voy', 20), ('mundo', 16), ('amigos', 15)]\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "keyword_kmeans = get_keywords_clusters(named_videoKM)\n",
    "for i, val in enumerate(keyword_kmeans):\n",
    "    print(\"Cluster: {}\\n Palabras clave: {}\\n----------------\".format(i, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo salió mal porque todos los clusters tienen a música como la palabra representativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      " Palabras clave: [('música', 97), ('país', 42), ('vídeo', 32), ('años', 25), ('voy', 23)]\n",
      "----------------\n",
      "Cluster: 1\n",
      " Palabras clave: [('música', 59), ('país', 26), ('años', 8), ('vídeo', 5), ('voy', 5)]\n",
      "----------------\n",
      "Cluster: 2\n",
      " Palabras clave: [('música', 71), ('país', 42), ('vídeo', 15), ('vamos', 11), ('años', 11)]\n",
      "----------------\n",
      "Cluster: 3\n",
      " Palabras clave: [('música', 52), ('país', 34), ('voy', 14), ('vídeo', 10), ('años', 6)]\n",
      "----------------\n",
      "Cluster: 4\n",
      " Palabras clave: [('música', 42), ('país', 22), ('años', 9), ('gobierno', 4), ('voy', 4)]\n",
      "----------------\n",
      "Cluster: 5\n",
      " Palabras clave: [('música', 62), ('país', 45), ('años', 30), ('vamos', 15), ('voy', 11)]\n",
      "----------------\n",
      "Cluster: 6\n",
      " Palabras clave: [('música', 103), ('país', 59), ('años', 25), ('vamos', 23), ('vídeo', 20)]\n",
      "----------------\n",
      "Cluster: 7\n",
      " Palabras clave: [('música', 103), ('país', 55), ('años', 40), ('vídeo', 18), ('voy', 18)]\n",
      "----------------\n",
      "Cluster: 8\n",
      " Palabras clave: [('música', 399), ('país', 250), ('años', 127), ('voy', 123), ('vamos', 75)]\n",
      "----------------\n",
      "Cluster: 9\n",
      " Palabras clave: [('música', 31), ('años', 28), ('país', 13), ('china', 6), ('gobierno', 5)]\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "keyword_S = get_keywords_clusters(named_videoS)\n",
    "for i, val in enumerate(keyword_S):\n",
    "    print(\"Cluster: {}\\n Palabras clave: {}\\n----------------\".format(i, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intento 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos comparar entre los diferentes clusters de cada intento para ver si coinciden algunos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos una intersección de clusters\n",
    "inter = [0,0,0,0,0,0,0,0,0,0]\n",
    "for c, docs in named_videoKM.items():\n",
    "    for id in docs:\n",
    "        if id in named_videoS[c]:\n",
    "            inter[c] += 1\n",
    "    inter[c] = {'C': c, \n",
    "                'Total video KM': len(docs),\n",
    "                'Total video S': len(named_videoS[c]),\n",
    "                'Compartidos': inter[c]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 0, 'Total video KM': 219, 'Total video S': 296, 'Compartidos': 17},\n",
       " {'C': 1, 'Total video KM': 84, 'Total video S': 134, 'Compartidos': 2},\n",
       " {'C': 2, 'Total video KM': 376, 'Total video S': 192, 'Compartidos': 25},\n",
       " {'C': 3, 'Total video KM': 61, 'Total video S': 143, 'Compartidos': 1},\n",
       " {'C': 4, 'Total video KM': 98, 'Total video S': 103, 'Compartidos': 1},\n",
       " {'C': 5, 'Total video KM': 1698, 'Total video S': 210, 'Compartidos': 140},\n",
       " {'C': 6, 'Total video KM': 188, 'Total video S': 313, 'Compartidos': 20},\n",
       " {'C': 7, 'Total video KM': 23, 'Total video S': 302, 'Compartidos': 2},\n",
       " {'C': 8, 'Total video KM': 230, 'Total video S': 1471, 'Compartidos': 136},\n",
       " {'C': 9, 'Total video KM': 299, 'Total video S': 112, 'Compartidos': 13}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
