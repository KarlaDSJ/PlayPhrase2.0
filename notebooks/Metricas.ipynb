{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar los dos modelos creados previamente primero nos centraremos en crear un conjunto de prueba siguiendo los siguientes pasos:\n",
    "\n",
    "1. Obtener un conjunto de oraciones variadas (C)\n",
    "    - Oraciones simples\n",
    "    - Oraciones complejas \n",
    "    - Oraciones con ruido\n",
    "\n",
    "2. TP - que recupere la query tal cual o lo más parecido\n",
    "    - La query (c in C) si se encuentra en corpus\n",
    "    - La query se encuentra parcialmente\n",
    "       (tomamos oraciones del corpus y le metemos ruido)\n",
    "       (tendríamos que revisar que el corpus si tenga la query parcial\n",
    "       y luego revisar los resultados, si la busqueda da resultados\n",
    "       pero en corpus no hay entonces es un falso positivo)\n",
    "\n",
    "\n",
    "3. TN - oraciones donde ninguna palabra está dentro del corpus\n",
    "    - Si regresa resultados es un falso negativo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"img/metricas.jpg\" width=\"70%\" alt=\"Metricas\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split #particiones\n",
    "import string\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el corpus original para seleccionar algunas oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt(path):\n",
    "    \"\"\"\n",
    "    Regresa una lista con el contenido de todos los archivos de un directorio\n",
    "\n",
    "    Args:\n",
    "        path (str): ruta de la carpeta\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    \n",
    "    for file in onlyfiles:\n",
    "        with open(path+\"/\"+file, 'rb') as f:\n",
    "            text.append(json.loads(f.read().decode('utf-8', 'replace')))\n",
    "    return text\n",
    "\n",
    "# Guardamos los subtitulos de todos los canales\n",
    "videos_original = get_txt(\"../corpus/data\")#Nota: no print de todo\n",
    "# Obtenemos el conjunto de test\n",
    "_, test = train_test_split(videos_original, test_size=0.05) #5%\n",
    "_, test = train_test_split(videos_original, test_size=0.05) #2.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtitles():\n",
    "    '''\n",
    "    Regresa los subtitulos del corpus\n",
    "    '''\n",
    "    test_subtitles = []\n",
    "    for chanel in test:\n",
    "        for video in chanel:\n",
    "            if 'subtitles' in video:\n",
    "                for s in video['subtitles']:\n",
    "                    test_subtitles.append(s['text'])\n",
    "    return test_subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del 2.5% de oraciones tomadas del corpus tomamos la mitad para meterles ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soltar imágenes textos vídeos algunos', 'que exista otra vida además de la', 'células básicamente una célula es un', 'ejercicios para modificar el atributo de', 'infinito por no hablar de que los', 'de perclorato muy tóxicas la exposición', 'extremos ya sea un agujero de gusano', 'para entrar en la fase 2 en la segunda', 'infectar otras células y limpia el campo', 'nuestros vídeos ya nos ayuda un montón'] 4744 4743\n"
     ]
    }
   ],
   "source": [
    "test_TP, test_TPR = train_test_split(get_subtitles(), test_size=0.5)\n",
    "print(test_TPR[:10], len(test_TPR), len(test_TP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soltar imágenes textos UOFoHI uso0Ob vídeos algunos', 'que exista otra Wl8dY8 vida además YIa9NP de la', 'SzxpRZ células básicamente una célula es 518zy7 un', 'ejercicios para N2LnNW modificar el atributo 4XCQtI de', 'infinito por no hablar de que Y4hQyV ZJBZXP los', 'Zpt6MU de perclorato VEAjM5 muy tóxicas la exposición', 'extremos ya sea y8qvc9 un agujero de zI6viV gusano', 'para entrar en la fase oYWMw0 2 en fMHaR0 la segunda', 'infectar otras células y limpia m1LEvD NYQxll el campo', 'nuestros vídeos ya nos ayuda VSKiqw jSNeyb un montón'] 4744\n"
     ]
    }
   ],
   "source": [
    "def insert(s, num):\n",
    "    \"\"\"\n",
    "    Agrega n cadenas aleatorias a una lista\n",
    "\n",
    "    Args:\n",
    "        s (list): lista de cadenas\n",
    "        num (int): número de cadenas aleatorias a insertar\n",
    "    \"\"\"\n",
    "    for _ in range(num):\n",
    "        noise = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(6))\n",
    "        ix = random.randint(0,len(s)-1)\n",
    "        s.insert(ix, noise)\n",
    "\n",
    "def make_noise():\n",
    "    \"\"\"\n",
    "    A cada oración del conjunto le agrega n cadenas aleatorias\n",
    "    \"\"\"\n",
    "    for i, sentence in enumerate(test_TPR):\n",
    "        s = sentence.split(\" \")\n",
    "        insert(s, 2)\n",
    "        test_TPR[i] = ' '.join(s)\n",
    "\n",
    "make_noise()\n",
    "print(test_TPR[:10], len(test_TPR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos 1.25% de oraciones con palabras que no están en el corpus de tal manera que el conjunto de prueba queda compuesto por:\n",
    "- 1.25% oraciones que se encuentran tal cual en el corpus\n",
    "- 1.25% oraciones que se encuentran  en el corpus pero con ruido\n",
    "- 0.625% oraciones que no comparten palabras con el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pNjqoS emchMs dfM1Ef cxBJh7 RJDbTr y29Kn0 TxCGAa CqrMvb wQ99Lc PzKkSW ', 'vn46SG JrrVQM POFCX6 tiDUMa IxY0gV ', 'jhk88X mDoQZI 02xtuz ', 'uxJ5jc LqOCSj nSODbT wMv8NX W57xf8 ', 'Zh25XY 10b3Ew vtRuqN 7XNZSk Iacqgg LMt9vE 6d4KKh h4oAvA PM4UQM rIBzIt ', 'wxwJ2d bRe5iw M2XQ9d U6gv5t OrW0UT HxEbhJ AJX6Mn 3WyVWI zYlL8Q FyCOb1 xXOvr2 fp36CV 4rZvOy wIojqL dRzvEp p1E7C0 brW1iH STI08e li93hH 80O0c0 ', 'Aurwut 7e9Kd2 rq6LEH sPkDEq Tfsy5t Uz5Bkb WqN0me jxSqK4 VxBWoF K1qTof THIyVL 0RVwOo c7J6JC eV6eRw i5XVXf lpN2gx xset6Y ehjgzc dcP6si 6PKxXu ', 'iLbyl4 xllOvL 7Tiz6k 83XYe0 ONmETg WTW9iR Vga8Zx x9qcqP plZzgC wWbxUH ', 'glIhY9 pxsht8 POTFfg ', 'W0QxIW gC2XRE n78bdo 9YUiCY lQACY5 '] 2371\n"
     ]
    }
   ],
   "source": [
    "def make_sentence():\n",
    "    \"\"\"\n",
    "    Crea un conjunto de cadenas aleatorias\n",
    "    \"\"\"\n",
    "    sentence = []\n",
    "    lg = [3,5,10,20]\n",
    "    for _ in range(len(test_TP)//2):\n",
    "        s = [\"\"]\n",
    "        insert(s, lg[random.randint(0,len(lg)-1)])\n",
    "        sentence.append(' '.join(s))\n",
    "    return sentence\n",
    "    \n",
    "test_TN = make_sentence()\n",
    "print(test_TN[:10], len(test_TN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = test_TP + test_TPR + test_TN\n",
    "pickle.dump(test_all, open(\"../pkl/test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['constantemente juntas todas esas',\n",
       " 'ciego y la evaluación científica para',\n",
       " 'el humano moderno surgió al menos 200',\n",
       " 'soltar imágenes textos UOFoHI uso0Ob vídeos algunos',\n",
       " 'que exista otra Wl8dY8 vida además YIa9NP de la',\n",
       " 'SzxpRZ células básicamente una célula es 518zy7 un',\n",
       " 'ejercicios para N2LnNW modificar el atributo 4XCQtI de',\n",
       " 'infinito por no hablar de que Y4hQyV ZJBZXP los',\n",
       " 'Zpt6MU de perclorato VEAjM5 muy tóxicas la exposición',\n",
       " 'extremos ya sea y8qvc9 un agujero de zI6viV gusano']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../pkl/test.pkl\", \"rb\") as f:\n",
    "    test_all = pickle.load(f)\n",
    "\n",
    "test_all[4740:4750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11858"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test[0] = \"holaa\"\n",
    "\n",
    "resp[0] = \"subtítulo encontrado dada la query test[0]\"\n",
    "\n",
    "guardas en un pickle resp"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
