{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar los dos modelos creados previamente primero nos centraremos en crear un conjunto de prueba siguiendo los siguientes pasos:\n",
    "\n",
    "1. Obtener un conjunto de oraciones variadas (C)\n",
    "    - Oraciones simples\n",
    "    - Oraciones complejas \n",
    "    - Oraciones con ruido\n",
    "\n",
    "2. TP - que recupere la query tal cual o lo más parecido\n",
    "    - La query (c in C) si se encuentra en corpus\n",
    "    - La query se encuentra parcialmente\n",
    "       (tomamos oraciones del corpus y le metemos ruido)\n",
    "       (tendríamos que revisar que el corpus si tenga la query parcial\n",
    "       y luego revisar los resultados, si la busqueda da resultados\n",
    "       pero en corpus no hay entonces es un falso positivo)\n",
    "\n",
    "\n",
    "3. TN - oraciones donde ninguna palabra está dentro del corpus\n",
    "    - Si regresa resultados es un falso negativo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"img/metricas.jpg\" width=\"70%\" alt=\"Metricas\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #particiones\n",
    "import string\n",
    "import random\n",
    "import pickle\n",
    "#Para el corpus\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el corpus original para seleccionar algunas oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': '13.596', 'dur': '1.752', 'text': '¿Adónde vas, Momo?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_original = Data(\"../corpus/data\")\n",
    "videos_original.corpus[0][0]['subtitles'][0]#Nota: no print de todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el conjunto de test\n",
    "_, test = train_test_split(videos_original.corpus, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtitles():\n",
    "    '''\n",
    "    Regresa los subtitulos del corpus\n",
    "    '''\n",
    "    test_subtitles = []\n",
    "    for chanel in test:\n",
    "        for video in chanel:\n",
    "            if 'subtitles' in video:\n",
    "                for s in video['subtitles']:\n",
    "                    test_subtitles.append(s['text'])\n",
    "    return test_subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del 2.5% de oraciones tomadas del corpus tomamos la mitad para meterles ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estable el rojo de doble hoja escuchen', 'me vea distinto voy a presionar para', 'nos vamos a conectar realmente está', 'sobrepasando los límites tomando riesgos', '[Música]', 'tu espíritu es evidente', 'tiene tanta imaginación como miedo de', 'tal vez ninguno de ellos y te querrá', 'tuve que traer a mi hermano a vivir', '[Música]'] 1814 1814\n"
     ]
    }
   ],
   "source": [
    "test_TP, test_TPR = train_test_split(get_subtitles(), test_size=0.5)\n",
    "print(test_TPR[:10], len(test_TPR), len(test_TP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estable el Krpvai rojo de doble hoja Yiq09t escuchen', 'me vea distinto YM9WvL voy a WmXDRl presionar para', 'nos vamos FvWJCa CuwjNU a conectar realmente está', 'WcKt0L sobrepasando los límites sQ7Bre tomando riesgos', 'lcIm6W tunOy4 [Música]', 'Q7qGDB tu 328igU espíritu es evidente', 'tiene k93N1s tanta h52ltC imaginación como miedo de', 'tal vez ninguno voKmKN de CqymG2 ellos y te querrá', 'tuve que 5by4Qg traer kNRISK a mi hermano a vivir', 'PpbZIn i41K3Y [Música]'] 1814\n"
     ]
    }
   ],
   "source": [
    "def insert(s, num):\n",
    "    \"\"\"\n",
    "    Agrega n cadenas aleatorias a una lista\n",
    "\n",
    "    Args:\n",
    "        s (list): lista de cadenas\n",
    "        num (int): número de cadenas aleatorias a insertar\n",
    "    \"\"\"\n",
    "    for _ in range(num):\n",
    "        noise = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(6))\n",
    "        ix = random.randint(0,len(s)-1)\n",
    "        s.insert(ix, noise)\n",
    "\n",
    "def make_noise():\n",
    "    \"\"\"\n",
    "    A cada oración del conjunto le agrega n cadenas aleatorias\n",
    "    \"\"\"\n",
    "    for i, sentence in enumerate(test_TPR):\n",
    "        s = sentence.split(\" \")\n",
    "        insert(s, 2)\n",
    "        test_TPR[i] = ' '.join(s)\n",
    "\n",
    "make_noise()\n",
    "print(test_TPR[:10], len(test_TPR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos 1.25% de oraciones con palabras que no están en el corpus de tal manera que el conjunto de prueba queda compuesto por:\n",
    "- 1.25% oraciones que se encuentran tal cual en el corpus\n",
    "- 1.25% oraciones que se encuentran  en el corpus pero con ruido\n",
    "- 0.625% oraciones que no comparten palabras con el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aDn0iN 2yFbJ1 iYySec UIV2nH WvbwKm ', 'DIm6hY lwDrf1 mAGUp5 ', 'zLPNEn e2KMX2 lWmPpC RwpiHX 0mNqTY j60FLh CMoPON p7aifF bWuCLr 9eQXHu ', 'HBu9cb DnDiVN DJUQTT s9DINu mEeRUJ 4FEUKw fmPMtA x2nrcC gOsFXC P8W64E ', 'KyEcMj I9iWB1 jc6Td1 ', 'Y0xPOl VjFXvb L26OJ7 KvKiYO Or9KJB Esz882 8PrcRL DNk53s HMfqzN FpueVf 2tnASF 2lR8cI 8Ls1w4 P3wUkM zbz3Qe SlNbra eQY1NG H7QlCe fLCJc9 VVpYVg ', 'E3Xyux yhqYwK 24tzkl ', 'PNjtxM AjP2HI liE5zy ', 'gAyhM4 7o64aj 5ONjIw G4q3GD NbU0k9 ', 'd4Uzpx KN4izO lfKZpu '] 907\n"
     ]
    }
   ],
   "source": [
    "def make_sentence():\n",
    "    \"\"\"\n",
    "    Crea un conjunto de cadenas aleatorias\n",
    "    \"\"\"\n",
    "    sentence = []\n",
    "    lg = [3,5,10,20]\n",
    "    for _ in range(len(test_TP)//2):\n",
    "        s = [\"\"]\n",
    "        insert(s, lg[random.randint(0,len(lg)-1)])\n",
    "        sentence.append(' '.join(s))\n",
    "    return sentence\n",
    "    \n",
    "test_TN = make_sentence()\n",
    "print(test_TN[:10], len(test_TN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = test_TP + test_TPR + test_TN\n",
    "pickle.dump(test_all, open(\"../pkl/test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blJsis 8eaxn6 asco',\n",
       " 'l0nrhs LEt41H [Aplausos]',\n",
       " 'NRKCrq vida como GZRafD detective aquí es donde vivo a',\n",
       " 'zpty5d LCNCRi más o menos',\n",
       " 'z1IRhf voy a comerte ZSquts vivo',\n",
       " 'vamos a celebrar con una gran fiesta qW7Kal RHrYMU un',\n",
       " 'estos son más CK4oNF que objetos V90QM1 y vestuarios',\n",
       " '15 mil 5cFBMT dólares Y8oMHy por favor sin el lado',\n",
       " 'mundo la apertura del concierto estará O9xVT4 fmqnb9 a',\n",
       " 'deberíamos 1GdCyN tratar de jFROLG averiguar dónde',\n",
       " 'Hz9q70 LxbqQR [Aplausos]',\n",
       " 'aparte están dSdqqk aEB6z2 las personas que desean',\n",
       " 'VAzBvh n96dw0 [Música]',\n",
       " 'FQzQ69 uh3qPs [Música]',\n",
       " 'caminan a 8goHyq fGBiAu madrid aplausos',\n",
       " 'OeigtJ maravilloso su reto será QGywUK el lograr con',\n",
       " 'X8Q3qV también tienen momentos s7c3OF turbios cuánto',\n",
       " 'fiE4Z6 6zxctO estuviste cerca',\n",
       " 'ella buscar a 5eKhqJ mi hermano y 6OeY4D tú vengas',\n",
       " 'su rShTIy i4yoCk cabeza verdad la mía es la cultura yo',\n",
       " 'ard0UB tienen fJX1b2 superpoderes somos superhéroes',\n",
       " 'el océano te IPtBNu eligió por soJ179 una razón',\n",
       " 'solo lo dice AUbZK0 es PSLO6j porque eres limonada lo',\n",
       " 'rLbXsM iSxW3w [Música]',\n",
       " 'dibujando yo creo DpOqfT uvKACz que siempre quise ser',\n",
       " 'xbU0PF y los payasos interpretan 9Dig40 sus papeles a',\n",
       " 'geGG3o tu ztXUCK papá tuvo un accidente',\n",
       " 'entonces tú MVfsd4 se quedarán givjXv aquí para',\n",
       " 'a9wcDz un Kt3wKk escarabajo',\n",
       " 'ave balancín creó la wh7RAE F93J9i escuela americana',\n",
       " 'QKbFkD kWgGp3 no',\n",
       " 'puedo llevarte a la FWAYRw estación 9U6nty de policía',\n",
       " 'momento yo c4H4Dg es K82anW que quería mostrarles a',\n",
       " 'Rn0yaB 8V1pOh [Música]',\n",
       " 'a Kqks0Y VhTxBn fondo',\n",
       " 'es muy emocionante 8I0nPz xpEDoZ estar a una ser que',\n",
       " 'aquí este es JmzapA un lugar seguro no hay VG9973 mix',\n",
       " '6af8iH la familia disney si ya DOr4uL se sabe que soy',\n",
       " 'también en el W6DE5v G8LgEl baile será mi primera cita',\n",
       " 'crack un rex RI0A7x es un verdadero gamer ya DgrqU1 sé',\n",
       " 'nada mi 7edaoL pequeño hermano dBjVoT doctor tiene',\n",
       " 'suficiente por ziUeYp RItpid los dos',\n",
       " 'la BCTV7I nqrEb4 tendencia del tipo',\n",
       " 'GU5TYf HLAt5u negocios',\n",
       " 'esta es la historia mi nombre es 0SPQjQ hi2pym raya',\n",
       " 'p2lxRN yzpdGQ ocultarlo',\n",
       " 'lo gXdSyP que fue lo QX21LR que es',\n",
       " 'continuar con lo gd9a5m que enamoró a la WZCcW3 gente',\n",
       " 'a veces hago mi vida sabes UIO3VZ como 853MZ9 un',\n",
       " 'cosas que GFYt3d tienen xMjeU7 todos en común veo']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../pkl/test.pkl\", \"rb\") as f:\n",
    "    test_all = pickle.load(f)\n",
    "\n",
    "test_all[3000:3050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4535"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veremos que tan bien recupera las oraciones de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(s1, s2):\n",
    "    \"\"\"\n",
    "    Regresa el número de palabras que conparten 2 cadenas\n",
    "\n",
    "    Args:\n",
    "        s1 (lst): lista de palabras de la cadena 1\n",
    "        s2 (lst): lista de palabras de la cadena 2\n",
    "    \"\"\"\n",
    "    val = 0\n",
    "    for i in s2: \n",
    "        if i in s1: val += 1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(\"a un lado oigan alejen a los demás viene\".split(), 'y fue porque íbamos a saltar de los'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para el caso de TFIDF cuando no encuentra coincidencias\n",
    "#(score = 0 para todas las cadenas)regresa lo siguiente:\n",
    "dummy_sentence = ['tu papá tuvo un accidente', 'te recuerdo que está', \n",
    "                  'aquí', 'estaba como rabioso con', \n",
    "                  'especial con lucas martín']\n",
    "\n",
    "def eval_sentence(query, resp):\n",
    "    \"\"\"\n",
    "    Evalúa los resultados obtenidos dada una query\n",
    "\n",
    "    Args:\n",
    "        query (str): query de prueba generada previamente\n",
    "        resp (list): lista con las primeras 5 respuestas obtenidas \n",
    "            por algún mecanismo de RI\n",
    "    Return:\n",
    "        (int): 0 cuando no encontró ninguna coincidencia\n",
    "               1 si encontró la query exacta y es el primer resultado\n",
    "               (0 - 1) si:\n",
    "                - Encuentra la query pero no es el primer resultado\n",
    "                le quitamos .1 por cada lugar que pasa y no está la query\n",
    "                - No se encuentra la query pero algunas palabras de la misma sí \n",
    "    \"\"\"\n",
    "    val = 0 \n",
    "    total = 0\n",
    "\n",
    "    if resp != dummy_sentence: \n",
    "        count = 0\n",
    "        for i, r in enumerate(resp):\n",
    "            if r == query: #si la encuentra val será como min .6\n",
    "                return  1 - (.1 * i)\n",
    "            total += len(r)\n",
    "            count += count_words(query.split(), r.split())\n",
    "            # si no la encuentra ve que tanto se parecen los resultados\n",
    "            val = count / total \n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos los 4 casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_sentence(\"avergonzado lo suficiente no apenas\",\n",
    "             ['avergonzado lo suficiente no apenas', \n",
    "             'pesados o polar no lo suficiente como', \n",
    "             'no vende suficiente leña lo siento pero', \n",
    "             'Como pueden ver, no me cuesta trabajo \\nestirar la masa porque descanso lo suficiente.', \n",
    "             'aún así no es suficiente porque lo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_sentence(\"avergonzado lo suficiente no apenas\",\n",
    "             ['pesados o polar no lo suficiente como', \n",
    "             'no vende suficiente leña lo siento pero', \n",
    "             'avergonzado lo suficiente no apenas', \n",
    "             'Como pueden ver, no me cuesta trabajo \\nestirar la masa porque descanso lo suficiente.', \n",
    "             'aún así no es suficiente porque lo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056910569105691054"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_sentence(\"a un lado oigan alejen a los demás viene\",   \n",
    "             ['Vámonos a casa.', \n",
    "             '¿Cómo ibas a saberlo?', \n",
    "             '¡Hola a todos!', \n",
    "             'Son fisuras\\na un infierno desconocido.', \n",
    "             'y fue porque íbamos a saltar de los'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_sentence(\"8eIqyc xwWsUF 3eHwS8 qE5XFM Tknsyj\",\n",
    "             ['tu papá tuvo un accidente', \n",
    "             'te recuerdo que está', \n",
    "             'aquí', \n",
    "             'estaba como rabioso con', \n",
    "             'especial con lucas martín'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all(resp):\n",
    "    \"\"\"\n",
    "    Evalua las respuestas de un modelo de la siguiente manera:\n",
    "        Si está en el conjunto 1 (original) debería de responder con 1\n",
    "            Si 1 o muy cerca de 1 TP++ else si 0 FN++\n",
    "        Si esta en el conjunto 2 (con ruido) debería responder con un número decimal\n",
    "            Si mayor a .5 TP++ else si menor a 5 FN++\n",
    "        Si está en el conjunto 3 (que no están) deberia responder con 0\n",
    "            Si 0 TN++ else si 1 FP++\n",
    "    \n",
    "    Args:\n",
    "        resp (list): cada entrada de la lista es una lista con 5 respuestas\n",
    "    \"\"\"\n",
    "    original_noise = zip(test[:3628], resp[:3628])\n",
    "    invent = zip(test[3629:-1], resp[3629:-1])\n",
    "    TP, FN, FP, TN = 0, 0, 0, 0\n",
    "    #Recuperamos las particiones\n",
    "    #Conjunto original y con ruido\n",
    "    for query, resp in original_noise:\n",
    "        r = eval_sentence(query, resp)\n",
    "        if r > 0.4:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN +=1\n",
    "    #Conjunto inventado\n",
    "    for query, resp in invent:\n",
    "        r = eval_sentence(query, resp)\n",
    "        if r == 0:\n",
    "            TN += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "    return TP, FN, FP, TN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(TP, FN, FP, TN):\n",
    "    \"\"\"\n",
    "    Realiza el cálculo de:\n",
    "    Sensitive, specificity, precision, \n",
    "    negative predictive value y accuracy \n",
    "\n",
    "    Args:\n",
    "        TP (int): True Positive\n",
    "        FN (int): False Negative\n",
    "        FP (int): False Positive\n",
    "        TN (int): True Negative\n",
    "    \"\"\"\n",
    "    pred = TP / (TP + FP)\n",
    "    rec =  TP / (TP + FN)\n",
    "    return {\"TP\": TP, \"FN\": FN, \"FP\": FP, \"TN\": TN,\n",
    "            \"Specificity\": TN / (TN + FP),\n",
    "            \"Negative predictive value\": TN / (TN + FN),\n",
    "            \"Precision\": pred,\n",
    "            \"Sensitive (recall)\": rec,\n",
    "            \"Accuracy\": (TP + TN) / (TP + TN + FP + FN),\n",
    "            \"F1\": 2*(pred * rec) / (pred + rec)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../pkl/test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos TF-IDF con videos por vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 529,\n",
       " 'FN': 3099,\n",
       " 'FP': 0,\n",
       " 'TN': 905,\n",
       " 'Specificity': 1.0,\n",
       " 'Negative predictive value': 0.22602397602397603,\n",
       " 'Precision': 1.0,\n",
       " 'Sensitive (recall)': 0.1458103638368247,\n",
       " 'Accuracy': 0.31634679020516215,\n",
       " 'F1': 0.2545104642771229}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../pkl/results.pkl\", \"rb\") as f:\n",
    "    test_results = pickle.load(f)\n",
    "\n",
    "TP, FN, FP, TN = eval_all(test_results)\n",
    "get_metrics(TP, FN, FP, TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos TF-IDF con videos por subtítulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': 1093,\n",
       " 'FN': 2535,\n",
       " 'FP': 0,\n",
       " 'TN': 905,\n",
       " 'Specificity': 1.0,\n",
       " 'Negative predictive value': 0.26308139534883723,\n",
       " 'Precision': 1.0,\n",
       " 'Sensitive (recall)': 0.3012679162072767,\n",
       " 'Accuracy': 0.44076770350761085,\n",
       " 'F1': 0.46303749205676764}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../pkl/resultsxOracion.pkl\", \"rb\") as f:\n",
    "    test_resultsxO = pickle.load(f)\n",
    "\n",
    "TP, FN, FP, TN = eval_all(test_resultsxO)\n",
    "get_metrics(TP, FN, FP, TN)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
