{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar los dos modelos creados previamente primero nos centraremos en crear un conjunto de prueba siguiendo los siguientes pasos:\n",
    "\n",
    "1. Obtener un conjunto de oraciones variadas (C)\n",
    "    - Oraciones simples\n",
    "    - Oraciones complejas \n",
    "    - Oraciones con ruido\n",
    "\n",
    "2. TP - que recupere la query tal cual o lo más parecido\n",
    "    - La query (c in C) si se encuentra en corpus\n",
    "    - La query se encuentra parcialmente\n",
    "       (tomamos oraciones del corpus y le metemos ruido)\n",
    "       (tendríamos que revisar que el corpus si tenga la query parcial\n",
    "       y luego revisar los resultados, si la busqueda da resultados\n",
    "       pero en corpus no hay entonces es un falso positivo)\n",
    "\n",
    "\n",
    "3. TN - oraciones donde ninguna palabra está dentro del corpus\n",
    "    - Si regresa resultados es un falso negativo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"img/metricas.jpg\" width=\"70%\" alt=\"Metricas\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/karla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/karla/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split #particiones\n",
    "import string\n",
    "import random\n",
    "import pickle\n",
    "#Para el corpus\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import Data \n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el corpus original para seleccionar algunas oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': '13.596', 'dur': '1.752', 'text': '¿Adónde vas, Momo?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_original = Data(\"../corpus/data\")\n",
    "videos_original.corpus[0][0]['subtitles'][0]#Nota: no print de todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el conjunto de test\n",
    "_, test = train_test_split(videos_original.corpus, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtitles():\n",
    "    '''\n",
    "    Regresa los subtitulos del corpus\n",
    "    '''\n",
    "    test_subtitles = []\n",
    "    for chanel in test:\n",
    "        for video in chanel:\n",
    "            if 'subtitles' in video:\n",
    "                for s in video['subtitles']:\n",
    "                    test_subtitles.append(s['text'])\n",
    "    return test_subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del 2.5% de oraciones tomadas del corpus tomamos la mitad para meterles ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estable el rojo de doble hoja escuchen', 'me vea distinto voy a presionar para', 'nos vamos a conectar realmente está', 'sobrepasando los límites tomando riesgos', '[Música]', 'tu espíritu es evidente', 'tiene tanta imaginación como miedo de', 'tal vez ninguno de ellos y te querrá', 'tuve que traer a mi hermano a vivir', '[Música]'] 1814 1814\n"
     ]
    }
   ],
   "source": [
    "test_TP, test_TPR = train_test_split(get_subtitles(), test_size=0.5)\n",
    "print(test_TPR[:10], len(test_TPR), len(test_TP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estable el Krpvai rojo de doble hoja Yiq09t escuchen', 'me vea distinto YM9WvL voy a WmXDRl presionar para', 'nos vamos FvWJCa CuwjNU a conectar realmente está', 'WcKt0L sobrepasando los límites sQ7Bre tomando riesgos', 'lcIm6W tunOy4 [Música]', 'Q7qGDB tu 328igU espíritu es evidente', 'tiene k93N1s tanta h52ltC imaginación como miedo de', 'tal vez ninguno voKmKN de CqymG2 ellos y te querrá', 'tuve que 5by4Qg traer kNRISK a mi hermano a vivir', 'PpbZIn i41K3Y [Música]'] 1814\n"
     ]
    }
   ],
   "source": [
    "def insert(s, num):\n",
    "    \"\"\"\n",
    "    Agrega n cadenas aleatorias a una lista\n",
    "\n",
    "    Args:\n",
    "        s (list): lista de cadenas\n",
    "        num (int): número de cadenas aleatorias a insertar\n",
    "    \"\"\"\n",
    "    for _ in range(num):\n",
    "        noise = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(6))\n",
    "        ix = random.randint(0,len(s)-1)\n",
    "        s.insert(ix, noise)\n",
    "\n",
    "def make_noise():\n",
    "    \"\"\"\n",
    "    A cada oración del conjunto le agrega n cadenas aleatorias\n",
    "    \"\"\"\n",
    "    for i, sentence in enumerate(test_TPR):\n",
    "        s = sentence.split(\" \")\n",
    "        insert(s, 2)\n",
    "        test_TPR[i] = ' '.join(s)\n",
    "\n",
    "make_noise()\n",
    "print(test_TPR[:10], len(test_TPR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos 1.25% de oraciones con palabras que no están en el corpus de tal manera que el conjunto de prueba queda compuesto por:\n",
    "- 1.25% oraciones que se encuentran tal cual en el corpus\n",
    "- 1.25% oraciones que se encuentran  en el corpus pero con ruido\n",
    "- 0.625% oraciones que no comparten palabras con el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aDn0iN 2yFbJ1 iYySec UIV2nH WvbwKm ', 'DIm6hY lwDrf1 mAGUp5 ', 'zLPNEn e2KMX2 lWmPpC RwpiHX 0mNqTY j60FLh CMoPON p7aifF bWuCLr 9eQXHu ', 'HBu9cb DnDiVN DJUQTT s9DINu mEeRUJ 4FEUKw fmPMtA x2nrcC gOsFXC P8W64E ', 'KyEcMj I9iWB1 jc6Td1 ', 'Y0xPOl VjFXvb L26OJ7 KvKiYO Or9KJB Esz882 8PrcRL DNk53s HMfqzN FpueVf 2tnASF 2lR8cI 8Ls1w4 P3wUkM zbz3Qe SlNbra eQY1NG H7QlCe fLCJc9 VVpYVg ', 'E3Xyux yhqYwK 24tzkl ', 'PNjtxM AjP2HI liE5zy ', 'gAyhM4 7o64aj 5ONjIw G4q3GD NbU0k9 ', 'd4Uzpx KN4izO lfKZpu '] 907\n"
     ]
    }
   ],
   "source": [
    "def make_sentence():\n",
    "    \"\"\"\n",
    "    Crea un conjunto de cadenas aleatorias\n",
    "    \"\"\"\n",
    "    sentence = []\n",
    "    lg = [3,5,10,20]\n",
    "    for _ in range(len(test_TP)//2):\n",
    "        s = [\"\"]\n",
    "        insert(s, lg[random.randint(0,len(lg)-1)])\n",
    "        sentence.append(' '.join(s))\n",
    "    return sentence\n",
    "    \n",
    "test_TN = make_sentence()\n",
    "print(test_TN[:10], len(test_TN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = test_TP + test_TPR + test_TN\n",
    "pickle.dump(test_all, open(\"../pkl/test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oi1dKf HEhvhB [Música]',\n",
       " 'pero PzIfte soy yo KXskXT contra el universo',\n",
       " 'necesitan un Bvp5LZ 1ZmrPp símbolo',\n",
       " 'calificación WjDxM8 5dAVMt moriremos',\n",
       " 's62khJ R91mh7 [Música]',\n",
       " 'iOXVZH GmTJZP [Música]',\n",
       " 'hay 9vLCld varios elementos mOKotu diferentes estamos',\n",
       " '40P4ey fgGkeV [Música]',\n",
       " 'y se l5tZgQ comió VhNATO las arañas',\n",
       " 'puedes ZD69Mt imitar a una gaviota y6ml8k notting hill',\n",
       " 'no kU7lFN 8CP5dx puedo ocultarlo más',\n",
       " 'quiero J2PyxX S9kglW ver lo primero de pensar',\n",
       " 'puedo adivinar qué lado F7R1Tl NB2VP7 quieres joyería',\n",
       " 'travieso faltan 48 QGIZjA 7kSQDw horas para navidad',\n",
       " '0PPoA3 Co4LdD la mañana',\n",
       " 'RZeGIi MvJsfp [Música]',\n",
       " 'SShalE wow eso es b7QQOl muy grande',\n",
       " 'ese traje oOWXN4 wdU4I0 póngase un pantalón que',\n",
       " 'encuentras a 2N7Grm DgKBu6 un diseñador con quien te',\n",
       " 'lwDibm 3WHKDA [Música]',\n",
       " 'aeZ7qG con el gaRBUI mundo real tiene mucho',\n",
       " 'quiero que tBqBKv encuentren la fuerza plo 1vXU9t 99 y',\n",
       " 'que mi esposa 6uz6Tg trata de decir que HrPB8g nos',\n",
       " 'casi MyZGFS cada momento de toda ANjarE tu vida',\n",
       " 'ustedes antes de hacer bE3znn gR3LqP el anuncio',\n",
       " '89gPuc qngN8Z cambie de forma los dragones pueden',\n",
       " 'OOQ6TY no cuIeZD para',\n",
       " 'que pDrbaA nada cambie N10txJ eso',\n",
       " 'abolBI SXopXW hasta que mis brazos estén',\n",
       " 'en 1YnHuG pzD8VU la ciencia corrobora mi hipótesis le',\n",
       " 'IpVNzM Fh9xwf [Música]',\n",
       " 'desear pero rTWmA2 NHU7Qi me falta una sola cosa',\n",
       " 'ZqX7ZV qM29qh para frozen habíamos creado a las dos',\n",
       " 'hacer moXzvr a Lxsg43 la gente feliz es mi propósito',\n",
       " 'con su c6PXEh D5vecN vida',\n",
       " 'mc1yHm tal ssgp19 vez',\n",
       " 'de rUy1IR una exclusiva qRfpVr organización secreta',\n",
       " 'QynTLs RSxdzm [Música]',\n",
       " 'verdad es que CTYDJo siento una héroe JWuM6j de marvel',\n",
       " 'para trabaja mucho Twv3Ng que no h13DPR tenemos tanto',\n",
       " 'a MdI50o x8Kpgc ver',\n",
       " 'y bOC8MQ terminará viviendo vwGH8C aquí para siempre',\n",
       " 'bKDFu4 gEw8h6 [Música]',\n",
       " 'silencio muchacho o Xlj0SC x877Vj te haré daño',\n",
       " 'hola bebé dónde lRdkdC VuwEfS están tus padres',\n",
       " 'obtenido cayó en el cañón del 3XilLz río vd6XkC snake',\n",
       " 'WB1XNJ acuerdo al plan y por último el YJawC2 árbol',\n",
       " 'izB32G hay muchos constantes JHhziS así que eso es',\n",
       " 'j3es4u me interesa una sola BmJx7U cosa',\n",
       " 'Zrf0yo KHl16U [Música]']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../pkl/test.pkl\", \"rb\") as f:\n",
    "    test_all = pickle.load(f)\n",
    "\n",
    "test_all[3000:3050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4535"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veremos que tan bien recupera las oraciones de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(s1, s2):\n",
    "    \"\"\"\n",
    "    Regresa el número de palabras que conparten 2 cadenas\n",
    "\n",
    "    Args:\n",
    "        s1 (lst): lista de palabras de la cadena 1\n",
    "        s2 (lst): lista de palabras de la cadena 2\n",
    "    \"\"\"\n",
    "    val = 0\n",
    "    for i in s2: \n",
    "        if i in s1: val += 1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(\"a un lado oigan alejen a los demás viene\".split(), 'y fue porque íbamos a saltar de los'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para el caso de TFIDF cuando no encuentra coincidencias\n",
    "#(score = 0 para todas las cadenas)regresa lo siguiente:\n",
    "dummy_sentence = ['tu papá tuvo un accidente', 'te recuerdo que está', \n",
    "                  'aquí', 'estaba como rabioso con', \n",
    "                  'especial con lucas martín']\n",
    "\n",
    "def eval_sentence(query, resp):\n",
    "    \"\"\"\n",
    "    Evalúa los resultados obtenidos dada una query\n",
    "\n",
    "    Args:\n",
    "        query (str): query de prueba generada previamente\n",
    "        resp (list): lista con las primeras 5 respuestas obtenidas \n",
    "            por algún mecanismo de RI\n",
    "    Return:\n",
    "        (int): 0 cuando no encontró ninguna coincidencia\n",
    "               1 si encontró la query exacta y es el primer resultado\n",
    "               (0 - 1) si:\n",
    "                - Encuentra la query pero no es el primer resultado\n",
    "                - No se encuentra la query pero algunas palabras de la misma sí \n",
    "    \"\"\"\n",
    "    val = 0 \n",
    "    total = 0\n",
    "\n",
    "    if resp != dummy_sentence: \n",
    "        if resp[0] == query:\n",
    "            val = 1\n",
    "        else:\n",
    "            count = 0\n",
    "            for r in resp:\n",
    "                total += len(r)\n",
    "                count += count_words(query.split(), r.split())\n",
    "            val = count / total \n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos los 3 casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_sentence(\"avergonzado lo suficiente no apenas\",\n",
    "             ['avergonzado lo suficiente no apenas', \n",
    "             'pesados o polar no lo suficiente como', \n",
    "             'no vende suficiente leña lo siento pero', \n",
    "             'Como pueden ver, no me cuesta trabajo \\nestirar la masa porque descanso lo suficiente.', \n",
    "             'aún así no es suficiente porque lo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056910569105691054"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_sentence(\"a un lado oigan alejen a los demás viene\",   \n",
    "             ['Vámonos a casa.', \n",
    "             '¿Cómo ibas a saberlo?', \n",
    "             '¡Hola a todos!', \n",
    "             'Son fisuras\\na un infierno desconocido.', \n",
    "             'y fue porque íbamos a saltar de los'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_sentence(\"8eIqyc xwWsUF 3eHwS8 qE5XFM Tknsyj\",\n",
    "             ['tu papá tuvo un accidente', \n",
    "             'te recuerdo que está', \n",
    "             'aquí', \n",
    "             'estaba como rabioso con', \n",
    "             'especial con lucas martín'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all(resp):\n",
    "    \"\"\"\n",
    "    Evalua las respuestas de un modelo de la siguiente manera:\n",
    "        Si está en el conjunto 1 (original) debería de responder con 1\n",
    "            Si 1 o muy cerca de 1 TP++ else si 0 FN++\n",
    "        Si esta en el conjunto 2 (con ruido) debería responder con un número decimal\n",
    "            Si mayor a .5 TP++ else si menor a 5 FN++\n",
    "        Si está en el conjunto 3 (que no están) deberia responder con 0\n",
    "            Si 0 TN++ else si 1 FP++\n",
    "    \n",
    "    Args:\n",
    "        resp (list): cada entrada de la lista es una lista con 5 respuestas\n",
    "    \"\"\"\n",
    "    TP, FN, FP, TN = 0, 0, 0, 0\n",
    "    #Recuperamos las particiones\n",
    "    #Conjunto original\n",
    "    for query, resp in zip(test[:1813], resp[:1813]):\n",
    "        r = eval_sentence(query, resp)\n",
    "        if r == 1:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN +=1\n",
    "    #Conjunto con ruido\n",
    "    for query, resp in zip(test[1814:3628], resp[1814:3628]):\n",
    "        r = eval_sentence(query, resp)\n",
    "        if r > 0.5:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN +=1\n",
    "    #Conjunto inventado\n",
    "    for query, resp in zip(test[3628:], resp[3628:]):\n",
    "        r = eval_sentence(query, resp)\n",
    "        if r == 0:\n",
    "            TN += 1\n",
    "        else:\n",
    "            FP +=1\n",
    "    return TP, FN, FP, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(TP, FN, FP, TN):\n",
    "    \"\"\"\n",
    "    Realiza el cálculo de:\n",
    "    Sensitive, specificity, precision, \n",
    "    negative predictive value y accuracy \n",
    "\n",
    "    Args:\n",
    "        TP (int): True Positive\n",
    "        FN (int): False Negative\n",
    "        FP (int): False Positive\n",
    "        TN (int): True Negative\n",
    "    \"\"\"\n",
    "    return {\"Sensitive\": TP / (TP + FN),\n",
    "            \"Specificity\": TN / (TN + FP),\n",
    "            \"Precision\": TP / (TP + FP),\n",
    "            \"Negative predictive value\": TN / (TN + FN),\n",
    "            \"Accuracy\": (TP + TN) / (TP + TN + FP + FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../pkl/test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos TF-IDF con videos por vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373 1440 0 0\n"
     ]
    }
   ],
   "source": [
    "with open(\"../pkl/results.pkl\", \"rb\") as f:\n",
    "    test_results = pickle.load(f)\n",
    "\n",
    "TP, FN, FP, TN = eval_all(test_results)\n",
    "#get_metrics(TP, FN, FP, TN)\n",
    "print(TP, FN, FP, TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos TF-IDF con videos por subtítulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951 862 0 0\n"
     ]
    }
   ],
   "source": [
    "with open(\"../pkl/resultsxOracion.pkl\", \"rb\") as f:\n",
    "    test_resultsxO = pickle.load(f)\n",
    "\n",
    "TP, FN, FP, TN = eval_all(test_resultsxO)\n",
    "#get_metrics(TP, FN, FP, TN)\n",
    "print(TP, FN, FP, TN)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
