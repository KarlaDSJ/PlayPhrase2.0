{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar los dos modelos creados previamente primero nos centraremos en crear un conjunto de prueba siguiendo los siguientes pasos:\n",
    "\n",
    "1. Obtener un conjunto de oraciones variadas (C)\n",
    "    - Oraciones simples\n",
    "    - Oraciones complejas \n",
    "    - Oraciones con ruido\n",
    "\n",
    "2. TP - que recupere la query tal cual o lo más parecido\n",
    "    - La query (c in C) si se encuentra en corpus\n",
    "    - La query se encuentra parcialmente\n",
    "       (tomamos oraciones del corpus y le metemos ruido)\n",
    "       (tendríamos que revisar que el corpus si tenga la query parcial\n",
    "       y luego revisar los resultados, si la busqueda da resultados\n",
    "       pero en corpus no hay entonces es un falso positivo)\n",
    "\n",
    "\n",
    "3. TN - oraciones donde ninguna palabra está dentro del corpus\n",
    "    - Si regresa resultados es un falso negativo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"img/metricas.jpg\" width=\"70%\" alt=\"Metricas\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split #particiones\n",
    "import string\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el corpus original para seleccionar algunas oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt(path):\n",
    "    \"\"\"\n",
    "    Regresa una lista con el contenido de todos los archivos de un directorio\n",
    "\n",
    "    Args:\n",
    "        path (str): ruta de la carpeta\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    \n",
    "    for file in onlyfiles:\n",
    "        with open(path+\"/\"+file, 'rb') as f:\n",
    "            text.append(json.loads(f.read().decode('utf-8', 'replace')))\n",
    "    return text\n",
    "\n",
    "# Guardamos los subtitulos de todos los canales\n",
    "videos_original = get_txt(\"../corpus/data\")#Nota: no print de todo\n",
    "# Obtenemos el conjunto de test\n",
    "_, test = train_test_split(videos_original, test_size=0.007) #5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtitles():\n",
    "    '''\n",
    "    Regresa los subtitulos del corpus\n",
    "    '''\n",
    "    test_subtitles = []\n",
    "    for chanel in test:\n",
    "        for video in chanel:\n",
    "            if 'subtitles' in video:\n",
    "                for s in video['subtitles']:\n",
    "                    test_subtitles.append(s['text'])\n",
    "    return test_subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del 2.5% de oraciones tomadas del corpus tomamos la mitad para meterles ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['descubrir todo aquello que te gusta', 'detrás de escena de cómo están hechos', 'bueno más o menos', 'estas películas es historia de mi', 'mismo idioma', 'competencia por decir tenemos audiciones', 'portafolio muerto', '[Música]', 'como es tener acceso exclusivo a grandes', 'donde mana los sueños que van'] 1814 1814\n"
     ]
    }
   ],
   "source": [
    "test_TP, test_TPR = train_test_split(get_subtitles(), test_size=0.5)\n",
    "print(test_TPR[:10], len(test_TPR), len(test_TP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['descubrir Y9zK4T todo aquello que te AXtyjr gusta', 'detrás XutpTq de escena de cómo están tK0PIg hechos', 'bueno más mCTdV4 qqTfE4 o menos', 'estas películas Fs38d8 es historia 1fHzOx de mi', 'qXAXH6 vyOh1z mismo idioma', 'competencia pb5X8F por nsB0iZ decir tenemos audiciones', '0MKtio fHPsNT portafolio muerto', 'Fo1GNF JBbZoF [Música]', 'como es tener acceso iibbdR zProHZ exclusivo a grandes', 'donde YgHLSP mana los pA8QME sueños que van'] 1814\n"
     ]
    }
   ],
   "source": [
    "def insert(s, num):\n",
    "    \"\"\"\n",
    "    Agrega n cadenas aleatorias a una lista\n",
    "\n",
    "    Args:\n",
    "        s (list): lista de cadenas\n",
    "        num (int): número de cadenas aleatorias a insertar\n",
    "    \"\"\"\n",
    "    for _ in range(num):\n",
    "        noise = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(6))\n",
    "        ix = random.randint(0,len(s)-1)\n",
    "        s.insert(ix, noise)\n",
    "\n",
    "def make_noise():\n",
    "    \"\"\"\n",
    "    A cada oración del conjunto le agrega n cadenas aleatorias\n",
    "    \"\"\"\n",
    "    for i, sentence in enumerate(test_TPR):\n",
    "        s = sentence.split(\" \")\n",
    "        insert(s, 2)\n",
    "        test_TPR[i] = ' '.join(s)\n",
    "\n",
    "make_noise()\n",
    "print(test_TPR[:10], len(test_TPR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos 1.25% de oraciones con palabras que no están en el corpus de tal manera que el conjunto de prueba queda compuesto por:\n",
    "- 1.25% oraciones que se encuentran tal cual en el corpus\n",
    "- 1.25% oraciones que se encuentran  en el corpus pero con ruido\n",
    "- 0.625% oraciones que no comparten palabras con el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bnDz4Z vULMUu qnYG0r jprEgi pvuvJq JX3bQF ssGsSh Bizp0T 6ilRIt 8eWyqO GVfXsW nvboUr EJFOK3 VRbl6q npKIoU BZj9FN RFf9g7 Kx7sv1 rTcMQS eObTui ', 'THwuqq 7q9yXL RGTevs ', 'rBlL2C SfPeKx Mhr1WT ziJTXi f0QJlT g7ORm3 2yKxwl KgeAua ONAECf HUbSib ', 'aClHOo Dpym7P hZ22hT 2RmlyO PU06cP Zuax8u 1Elo9d ac24UI cIpuzN EAztti ', 'ePSvZY pRNBfZ 4UsmiA 1pEjgf 7DHVAJ BhvZYH SJKwZ7 lmOzl9 oEvNr3 pTnRau ', 'zmn7Tm YNN7QL pdiUJa lvJl64 lj6z6l XhocVQ 6i118x xV9vrK 6p0Mko rmCGFP KcCKNe VlzynS Y8Mz6E i2XIDa 0EUo0N 3Cfq0C iB7jjy IZHVQK V9oNhV yPY1gR ', 'bLJQeL lPTMG3 QXVI2T BZR1EG T34yGc OF2bwm 3Sd19V jQj3vb zitnPD 5qJyTO ', '66m5pA TW7yQm 1cYFUf DgNXJM P4a4DJ 2LmfNq TV3hu5 jkOIOv 8K0oOH 3GBJco ', '1vQvmz NDi2hb JahNiu BedsZJ 7GChSI 7hYMmu JIS8XH KgT0DJ E8VZCH WFv5qC euOYyT 0oi7Up jYLmcV OxKoNt zD6Gae oxGau6 0L7gZC BgqUzw O2gyev IVlPWd ', 'Lsx61H qTH8JD 7TbByM 80M8ba D90Nih '] 907\n"
     ]
    }
   ],
   "source": [
    "def make_sentence():\n",
    "    \"\"\"\n",
    "    Crea un conjunto de cadenas aleatorias\n",
    "    \"\"\"\n",
    "    sentence = []\n",
    "    lg = [3,5,10,20]\n",
    "    for _ in range(len(test_TP)//2):\n",
    "        s = [\"\"]\n",
    "        insert(s, lg[random.randint(0,len(lg)-1)])\n",
    "        sentence.append(' '.join(s))\n",
    "    return sentence\n",
    "    \n",
    "test_TN = make_sentence()\n",
    "print(test_TN[:10], len(test_TN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = test_TP + test_TPR + test_TN\n",
    "pickle.dump(test_all, open(\"../pkl/test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blJsis 8eaxn6 asco',\n",
       " 'l0nrhs LEt41H [Aplausos]',\n",
       " 'NRKCrq vida como GZRafD detective aquí es donde vivo a',\n",
       " 'zpty5d LCNCRi más o menos',\n",
       " 'z1IRhf voy a comerte ZSquts vivo',\n",
       " 'vamos a celebrar con una gran fiesta qW7Kal RHrYMU un',\n",
       " 'estos son más CK4oNF que objetos V90QM1 y vestuarios',\n",
       " '15 mil 5cFBMT dólares Y8oMHy por favor sin el lado',\n",
       " 'mundo la apertura del concierto estará O9xVT4 fmqnb9 a',\n",
       " 'deberíamos 1GdCyN tratar de jFROLG averiguar dónde',\n",
       " 'Hz9q70 LxbqQR [Aplausos]',\n",
       " 'aparte están dSdqqk aEB6z2 las personas que desean',\n",
       " 'VAzBvh n96dw0 [Música]',\n",
       " 'FQzQ69 uh3qPs [Música]',\n",
       " 'caminan a 8goHyq fGBiAu madrid aplausos',\n",
       " 'OeigtJ maravilloso su reto será QGywUK el lograr con',\n",
       " 'X8Q3qV también tienen momentos s7c3OF turbios cuánto',\n",
       " 'fiE4Z6 6zxctO estuviste cerca',\n",
       " 'ella buscar a 5eKhqJ mi hermano y 6OeY4D tú vengas',\n",
       " 'su rShTIy i4yoCk cabeza verdad la mía es la cultura yo',\n",
       " 'ard0UB tienen fJX1b2 superpoderes somos superhéroes',\n",
       " 'el océano te IPtBNu eligió por soJ179 una razón',\n",
       " 'solo lo dice AUbZK0 es PSLO6j porque eres limonada lo',\n",
       " 'rLbXsM iSxW3w [Música]',\n",
       " 'dibujando yo creo DpOqfT uvKACz que siempre quise ser',\n",
       " 'xbU0PF y los payasos interpretan 9Dig40 sus papeles a',\n",
       " 'geGG3o tu ztXUCK papá tuvo un accidente',\n",
       " 'entonces tú MVfsd4 se quedarán givjXv aquí para',\n",
       " 'a9wcDz un Kt3wKk escarabajo',\n",
       " 'ave balancín creó la wh7RAE F93J9i escuela americana',\n",
       " 'QKbFkD kWgGp3 no',\n",
       " 'puedo llevarte a la FWAYRw estación 9U6nty de policía',\n",
       " 'momento yo c4H4Dg es K82anW que quería mostrarles a',\n",
       " 'Rn0yaB 8V1pOh [Música]',\n",
       " 'a Kqks0Y VhTxBn fondo',\n",
       " 'es muy emocionante 8I0nPz xpEDoZ estar a una ser que',\n",
       " 'aquí este es JmzapA un lugar seguro no hay VG9973 mix',\n",
       " '6af8iH la familia disney si ya DOr4uL se sabe que soy',\n",
       " 'también en el W6DE5v G8LgEl baile será mi primera cita',\n",
       " 'crack un rex RI0A7x es un verdadero gamer ya DgrqU1 sé',\n",
       " 'nada mi 7edaoL pequeño hermano dBjVoT doctor tiene',\n",
       " 'suficiente por ziUeYp RItpid los dos',\n",
       " 'la BCTV7I nqrEb4 tendencia del tipo',\n",
       " 'GU5TYf HLAt5u negocios',\n",
       " 'esta es la historia mi nombre es 0SPQjQ hi2pym raya',\n",
       " 'p2lxRN yzpdGQ ocultarlo',\n",
       " 'lo gXdSyP que fue lo QX21LR que es',\n",
       " 'continuar con lo gd9a5m que enamoró a la WZCcW3 gente',\n",
       " 'a veces hago mi vida sabes UIO3VZ como 853MZ9 un',\n",
       " 'cosas que GFYt3d tienen xMjeU7 todos en común veo']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../pkl/test.pkl\", \"rb\") as f:\n",
    "    test_all = pickle.load(f)\n",
    "\n",
    "test_all[3000:3050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4535"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test[0] = \"holaa\"\n",
    "\n",
    "resp[0] = \"subtítulo encontrado dada la query test[0]\"\n",
    "\n",
    "guardas en un pickle resp"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
