{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar los dos modelos creados previamente primero nos centraremos en crear un conjunto de prueba siguiendo los siguientes pasos:\n",
    "\n",
    "1. Obtener un conjunto de oraciones variadas (C)\n",
    "    - Oraciones simples\n",
    "    - Oraciones complejas \n",
    "    - Oraciones con ruido\n",
    "\n",
    "2. TP - que recupere la query tal cual o lo más parecido\n",
    "    - La query (c in C) si se encuentra en corpus\n",
    "    - La query se encuentra parcialmente\n",
    "       (tomamos oraciones del corpus y le metemos ruido)\n",
    "       (tendríamos que revisar que el corpus si tenga la query parcial\n",
    "       y luego revisar los resultados, si la busqueda da resultados\n",
    "       pero en corpus no hay entonces es un falso positivo)\n",
    "\n",
    "\n",
    "3. TN - oraciones donde ninguna palabra está dentro del corpus\n",
    "    - Si regresa resultados es un falso negativo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"img/metricas.jpg\" width=\"70%\" alt=\"Metricas\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split #particiones\n",
    "import string\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el corpus original para seleccionar algunas oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt(path):\n",
    "    \"\"\"\n",
    "    Regresa una lista con el contenido de todos los archivos de un directorio\n",
    "\n",
    "    Args:\n",
    "        path (str): ruta de la carpeta\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    \n",
    "    for file in onlyfiles:\n",
    "        with open(path+\"/\"+file, 'rb') as f:\n",
    "            text.append(json.loads(f.read().decode('utf-8', 'replace')))\n",
    "    return text\n",
    "\n",
    "# Guardamos los subtitulos de todos los canales\n",
    "videos_original = get_txt(\"../corpus/data\")#Nota: no print de todo\n",
    "# Obtenemos el conjunto de test\n",
    "_, test = train_test_split(videos_original, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtitles():\n",
    "    '''\n",
    "    Regresa los subtitulos del corpus\n",
    "    '''\n",
    "    test_subtitles = []\n",
    "    for chanel in test:\n",
    "        for video in chanel:\n",
    "            if 'subtitles' in video:\n",
    "                for s in video['subtitles']:\n",
    "                    test_subtitles.append(s['text'])\n",
    "    return test_subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del 20% de oraciones tomadas del corpus tomamos la mitad para meterles ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tampoco a ver ni que te estuvieras comiendo una mierda tio. (se pasan)', 'thanks to her marriage to Tom Buchanan,', 'vídeo va a gustar o no no tengo ni idea', 'tranquilo, yo solo comentando aquí un par de mierdas con un buen zumito. Que por cierto no tengo así que hoy', 'Soy su asesor personal', 'publicidad allá donde vas pero yo soy un', 'En este caso, la presa y los sedimentos tóxicos detrás de ella.', 'esto ya directamente se lamenta del', 'La memoria RAM, como les mostré en el episodio anterior, está por fuera del CPU como un componente individual, y se', 'menos de un segundo esta mujer es vil y'] 83029 83028\n"
     ]
    }
   ],
   "source": [
    "test_TP, test_TPR = train_test_split(get_subtitles(), test_size=0.5)\n",
    "print(test_TPR[:10], len(test_TPR), len(test_TP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tampoco a E9VXoX ver UWvOST ni que te ckc6Z8 estuvieras comiendo una mierda KejDt7 tio. (se pasan)', 'Dapiol thanks to her marriage to OMrBIL PhrGmF Tom MSChu0 Buchanan,', 'vídeo 7VjRQy va gkxhip a gustar o NSe2FT cSMCob no no tengo ni idea', 'tranquilo, yo solo comentando aquí ivQLHX un par de mierdas qJ9FBv con un buen AwbyfS zumito. hph8VN Que por cierto no tengo así que hoy', 'LzT7w5 PzkfzK 7N9axN Soy su 0jLzLc asesor personal', 'CQ49xV publicidad allá donde zlDpAP Sv6vy9 vas pero OeFACv yo soy un', 'qHiN72 En este caso, AsJAE3 la zgqEVr zv6Hau presa y los sedimentos tóxicos detrás de ella.', 'iWmYPi 5Grmtb esto ya A7hdFT directamente 3RWVAv se lamenta del', 'La memoria RAM, como rOoBLA les mostré en vUMIFL el episodio anterior, está por fuera del CPU como un componente individual, yfQRLh BF9wRJ y se', 'menos de un segundo JddwNs esta tHkiOD mujer Tosoxy es vil 9IXo6D y'] 83029\n"
     ]
    }
   ],
   "source": [
    "def insert(s, num):\n",
    "    \"\"\"\n",
    "    Agrega n cadenas aleatorias a una lista\n",
    "\n",
    "    Args:\n",
    "        s (list): lista de cadenas\n",
    "        num (int): número de cadenas aleatorias a insertar\n",
    "    \"\"\"\n",
    "    for _ in range(num):\n",
    "        noise = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(6))\n",
    "        ix = random.randint(0,len(s)-1)\n",
    "        s.insert(ix, noise)\n",
    "\n",
    "def make_noise():\n",
    "    \"\"\"\n",
    "    A cada oración del conjunto le agrega n cadenas aleatorias\n",
    "    \"\"\"\n",
    "    for i, sentence in enumerate(test_TPR):\n",
    "        s = sentence.split(\" \")\n",
    "        insert(s, 4)\n",
    "        test_TPR[i] = ' '.join(s)\n",
    "\n",
    "make_noise()\n",
    "print(test_TPR[:10], len(test_TPR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos 10% de oraciones con palabras que no están en el corpus de tal manera que el conjunto de prueba (10% del corpus original) queda compuesto por:\n",
    "- 10% oraciones que se encuentran tal cual en el corpus\n",
    "- 10% oraciones que se encuentran  en el corpus pero con ruido\n",
    "- 10% oraciones que no comparten palabras con el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LpeDOm qfY79I OxePqV VHvCmk LLzJUL ', 'VMShrk pOJqbo jUER8t 5Gdfzw qYpasH ', 'vScHy7 idUVmZ 8QEFTc WmzhyL k2cGaT BBSWI0 I2y9wJ vNvgv3 13kBjj YoGJcH aocQuk 4qr4h5 7QEp5C zTWIYE NtIskf KFmOih cHRBZK 5DzoUx zre7IW kCKnUH ', 'sFCCOI peMUZn Xr9udl rkyvgz wa3SM4 ', 'qk78SS cVKGmy lAMxAT ', 'dBv1eN iLiPzJ PKFQVB ', 'iQYc46 1EmuiQ fepjqQ 8XAl1o 5NlSQg ddT6Fi ZunsZ3 pHMBqA wiuaut x4CyfQ ', 'UL6OnR nf2OGT QRCw2Q U8FUPL nVREvL Gx4lqb 5YPQ2x NoqWUv P86c5d hSSSrN VeC2Z0 XTTc0a 5whKsq Bb9O35 zNVfb5 nAjThh fsjpn2 TIwU1a RgTE9D n6ixvb ', 'e3LdDr 85YCx7 OEydOA ', 'D5I2uP d3RZRX uDIjFZ 4CHWjF 2uqptw '] 83028\n"
     ]
    }
   ],
   "source": [
    "def make_sentence():\n",
    "    \"\"\"\n",
    "    Crea un conjunto de cadenas aleatorias\n",
    "    \"\"\"\n",
    "    sentence = []\n",
    "    lg = [3,5,10,20]\n",
    "    for _ in range(len(test_TP)):\n",
    "        s = [\"\"]\n",
    "        insert(s, lg[random.randint(0,len(lg)-1)])\n",
    "        sentence.append(' '.join(s))\n",
    "    return sentence\n",
    "    \n",
    "test_TN = make_sentence()\n",
    "print(test_TN[:10], len(test_TN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = test_TP + test_TPR + test_TN\n",
    "pickle.dump(test_all, open(\"../pkl/test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uno podría decir 1933,\\ncuando Hitler ascendió al poder,',\n",
       " 'Si imaginamos la economía en su coche, a continuación, PIB,\\nel empleo y la inflación son los medidores. UN',\n",
       " 'a tener que esquivar así que se complica',\n",
       " 'Tampoco a E9VXoX ver UWvOST ni que te ckc6Z8 estuvieras comiendo una mierda KejDt7 tio. (se pasan)',\n",
       " 'Dapiol thanks to her marriage to OMrBIL PhrGmF Tom MSChu0 Buchanan,',\n",
       " 'vídeo 7VjRQy va gkxhip a gustar o NSe2FT cSMCob no no tengo ni idea',\n",
       " 'tranquilo, yo solo comentando aquí ivQLHX un par de mierdas qJ9FBv con un buen AwbyfS zumito. hph8VN Que por cierto no tengo así que hoy',\n",
       " 'LzT7w5 PzkfzK 7N9axN Soy su 0jLzLc asesor personal',\n",
       " 'CQ49xV publicidad allá donde zlDpAP Sv6vy9 vas pero OeFACv yo soy un',\n",
       " 'qHiN72 En este caso, AsJAE3 la zgqEVr zv6Hau presa y los sedimentos tóxicos detrás de ella.',\n",
       " 'iWmYPi 5Grmtb esto ya A7hdFT directamente 3RWVAv se lamenta del',\n",
       " 'La memoria RAM, como rOoBLA les mostré en vUMIFL el episodio anterior, está por fuera del CPU como un componente individual, yfQRLh BF9wRJ y se',\n",
       " 'menos de un segundo JddwNs esta tHkiOD mujer Tosoxy es vil 9IXo6D y',\n",
       " 'indefenso, dependiente, que KbZNln depende de otros C3XV9O para cuidar XbxqE4 1vImE0 de ellos, para tomar decisiones por ellos.',\n",
       " 'tenemos una responsabilidad epistemológica solo de WmhgMi creer qZNYXV en cosas de las que tengamos mZlflt YN1apv evidencia.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../pkl/test.pkl\", \"rb\") as f:\n",
    "    test_all = pickle.load(f)\n",
    "\n",
    "test_all[83025:83040]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249085"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test[0] = \"holaa\"\n",
    "\n",
    "resp[0] = \"subtítulo encontrado dada la query test[0]\"\n",
    "\n",
    "guardas en un pickle resp"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
